{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63582be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras                            \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34bc4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "font_list\n",
    "plt.rcParams['font.family'] = 'GULIM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1280980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34748\n",
      "안검내반증\n",
      "0        안검내반증\n",
      "1        안검내반증\n",
      "2        안검내반증\n",
      "3        안검내반증\n",
      "4        안검내반증\n",
      "         ...  \n",
      "34743      핵경화\n",
      "34744      핵경화\n",
      "34745      핵경화\n",
      "34746      핵경화\n",
      "34747      핵경화\n",
      "Name: Label, Length: 34748, dtype: object\n",
      "0        안검내반증\n",
      "1        안검내반증\n",
      "2        안검내반증\n",
      "3        안검내반증\n",
      "4        안검내반증\n",
      "         ...  \n",
      "34743      핵경화\n",
      "34744      핵경화\n",
      "34745      핵경화\n",
      "34746      핵경화\n",
      "34747      핵경화\n",
      "Name: Label, Length: 34748, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\안검...</td>\n",
       "      <td>안검염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\안검...</td>\n",
       "      <td>안검염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...</td>\n",
       "      <td>핵경화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...</td>\n",
       "      <td>핵경화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...</td>\n",
       "      <td>핵경화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filepath Label\n",
       "0  E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\안검...   안검염\n",
       "1  E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\안검...   안검염\n",
       "2  E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...   핵경화\n",
       "3  E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...   핵경화\n",
       "4  E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반\\핵경...   핵경화"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_ = Path('E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반')\n",
    "dir_val = Path ('E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반')\n",
    "filepaths = list(dir_.glob(r'**/*.jpg'))\n",
    "filepaths_val = list (dir_val.glob(r'**/*.jpg'))\n",
    "print(len(filepaths))\n",
    "print(str(filepaths[6]).split(\"\\\\\")[-3])\n",
    "def proc_img(filepath):\n",
    "    \"\"\"\n",
    "   \t\t이미지데이터의 경로와 label데이터로 데이터프레임 만들기 \n",
    "    \"\"\"\n",
    "\n",
    "    labels = [str(filepath[i]).split(\"\\\\\")[-3] \\\n",
    "              for i in range(len(filepath))]\n",
    "    \n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    print(labels)\n",
    "\n",
    "    # 경로와 라벨 concatenate\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # index 재설정\n",
    "    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = proc_img(filepaths)\n",
    "df_var = proc_img(filepaths_val)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "302e50d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          안검염\n",
      "1          안검염\n",
      "2          핵경화\n",
      "3          핵경화\n",
      "4          핵경화\n",
      "         ...  \n",
      "34743      유루증\n",
      "34744      핵경화\n",
      "34745      핵경화\n",
      "34746      유루증\n",
      "34747    안검내반증\n",
      "Name: Label, Length: 34748, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "print(df.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3daf2172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40466 files belonging to 5 classes.\n",
      "Using 8094 files for training.\n",
      "Found 40466 files belonging to 5 classes.\n",
      "Using 8093 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#각각 트레이닝 세트 validation set 구현\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dir_,\n",
    "  validation_split=0.8,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dir_val,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f315682",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ce9a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036491532 1.0\n"
     ]
    }
   ],
   "source": [
    "#rescaling 전처리 레이어를 생성하는 코드\n",
    "\n",
    "# 전처리 레이어 생성, 0과 1 사이의 범위를 1/255 스케일 팩터로 사용\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255) \n",
    "\n",
    "#이 코드는 train_ds 데이터셋의 모든 이미지에 대해 normalization_layer를 적용하여 정규화된 데이터셋 normalized_ds를 생성합니다.\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#normalized_ds에서 첫 번째 배치의 이미지와 레이블을 가져옵니다.\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "\n",
    "first_image = image_batch[0]\n",
    "# 정규화된 이미지의 최소 및 최대 픽셀 값을 출력합니다\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f2249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "#텐서 플로우의 Sequential 모델을 사용\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92533d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b18ee521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_5 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 90, 90, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 45, 45, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,285\n",
      "Trainable params: 3,989,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98f5a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU를 사용한 학습\n",
      "Epoch 1/10\n",
      "253/253 [==============================] - 64s 252ms/step - loss: 0.8213 - accuracy: 0.6658 - val_loss: 1.3174 - val_accuracy: 0.4897\n",
      "Epoch 2/10\n",
      "253/253 [==============================] - 63s 251ms/step - loss: 0.6202 - accuracy: 0.7575 - val_loss: 1.5059 - val_accuracy: 0.4925\n",
      "Epoch 3/10\n",
      "253/253 [==============================] - 76s 299ms/step - loss: 0.4483 - accuracy: 0.8411 - val_loss: 1.5196 - val_accuracy: 0.4757\n",
      "Epoch 4/10\n",
      "253/253 [==============================] - 62s 247ms/step - loss: 0.3453 - accuracy: 0.8831 - val_loss: 1.7456 - val_accuracy: 0.4757\n",
      "Epoch 5/10\n",
      "253/253 [==============================] - 62s 247ms/step - loss: 0.2993 - accuracy: 0.9052 - val_loss: 1.9567 - val_accuracy: 0.4594\n",
      "Epoch 6/10\n",
      "253/253 [==============================] - 62s 247ms/step - loss: 0.2638 - accuracy: 0.9104 - val_loss: 1.8423 - val_accuracy: 0.4821\n",
      "Epoch 7/10\n",
      "253/253 [==============================] - 62s 246ms/step - loss: 0.2419 - accuracy: 0.9196 - val_loss: 1.9045 - val_accuracy: 0.4752\n",
      "Epoch 8/10\n",
      "253/253 [==============================] - 62s 246ms/step - loss: 0.2274 - accuracy: 0.9203 - val_loss: 2.0893 - val_accuracy: 0.4745\n",
      "Epoch 9/10\n",
      "253/253 [==============================] - 62s 245ms/step - loss: 0.2039 - accuracy: 0.9259 - val_loss: 1.9384 - val_accuracy: 0.4758\n",
      "Epoch 10/10\n",
      "253/253 [==============================] - 64s 254ms/step - loss: 0.1988 - accuracy: 0.9266 - val_loss: 1.9679 - val_accuracy: 0.4804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2502e6106a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds,epochs=10)\n",
    "#질문 사항 어째서 테스트와 validation이 같은 데이터인데 이렇게 차이가 나지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "883e30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40466 images belonging to 5 classes.\n",
      "Found 40466 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "1264/1264 [==============================] - 763s 603ms/step - loss: 1.2068 - accuracy: 0.4728 - val_loss: 1.1371 - val_accuracy: 0.5041\n",
      "Epoch 2/10\n",
      "1264/1264 [==============================] - 452s 357ms/step - loss: 1.1155 - accuracy: 0.5148 - val_loss: 1.0768 - val_accuracy: 0.5311\n",
      "Epoch 3/10\n",
      "1264/1264 [==============================] - 457s 362ms/step - loss: 1.0735 - accuracy: 0.5333 - val_loss: 1.0199 - val_accuracy: 0.5610\n",
      "Epoch 4/10\n",
      "1264/1264 [==============================] - 448s 354ms/step - loss: 1.0458 - accuracy: 0.5481 - val_loss: 1.0193 - val_accuracy: 0.5625\n",
      "Epoch 5/10\n",
      "1264/1264 [==============================] - 440s 348ms/step - loss: 1.0189 - accuracy: 0.5633 - val_loss: 0.9714 - val_accuracy: 0.5822\n",
      "Epoch 6/10\n",
      "1264/1264 [==============================] - 445s 352ms/step - loss: 0.9934 - accuracy: 0.5719 - val_loss: 0.9405 - val_accuracy: 0.5985\n",
      "Epoch 7/10\n",
      "1264/1264 [==============================] - 440s 348ms/step - loss: 0.9719 - accuracy: 0.5835 - val_loss: 0.9102 - val_accuracy: 0.6110\n",
      "Epoch 8/10\n",
      "1264/1264 [==============================] - 438s 347ms/step - loss: 0.9508 - accuracy: 0.5922 - val_loss: 0.8848 - val_accuracy: 0.6244\n",
      "Epoch 9/10\n",
      "1264/1264 [==============================] - 439s 347ms/step - loss: 0.9322 - accuracy: 0.6006 - val_loss: 0.8871 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "1264/1264 [==============================] - 476s 376ms/step - loss: 0.9155 - accuracy: 0.6084 - val_loss: 0.8441 - val_accuracy: 0.6378\n",
      "1265/1265 [==============================] - 112s 88ms/step - loss: 0.8441 - accuracy: 0.6378\n",
      "Test loss: 0.844117283821106\n",
      "Test accuracy: 0.6377946734428406\n"
     ]
    }
   ],
   "source": [
    "#레이어 수정 버전. Sequential 모델 CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set the path to your dataset\n",
    "train_data_dir = 'E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반'\n",
    "test_data_dir = 'E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반'\n",
    "\n",
    "# Set the image dimensions and batch size\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation for training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Rescaling for test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.samples // batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=test_generator,\n",
    "          validation_steps=test_generator.samples // batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(test_generator)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760cf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40466 images belonging to 5 classes.\n",
      "Found 40466 images belonging to 5 classes.\n",
      "Found 6671 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "1264/1264 [==============================] - 5032s 4s/step - loss: 1.1506 - accuracy: 0.5206 - val_loss: 1.0647 - val_accuracy: 0.5547\n",
      "Epoch 2/10\n",
      "1264/1264 [==============================] - 5006s 4s/step - loss: 1.0372 - accuracy: 0.5595 - val_loss: 0.9926 - val_accuracy: 0.5814\n",
      "Epoch 3/10\n",
      "1264/1264 [==============================] - 5258s 4s/step - loss: 1.0011 - accuracy: 0.5764 - val_loss: 0.9670 - val_accuracy: 0.5959\n",
      "Epoch 4/10\n",
      "1264/1264 [==============================] - 5554s 4s/step - loss: 0.9704 - accuracy: 0.5885 - val_loss: 0.9399 - val_accuracy: 0.5990\n",
      "Epoch 5/10\n",
      "1264/1264 [==============================] - 5602s 4s/step - loss: 0.9462 - accuracy: 0.5997 - val_loss: 0.9002 - val_accuracy: 0.6227\n",
      "Epoch 6/10\n",
      "1264/1264 [==============================] - 5573s 4s/step - loss: 0.9282 - accuracy: 0.6081 - val_loss: 0.8998 - val_accuracy: 0.6206\n",
      "Epoch 7/10\n",
      "1264/1264 [==============================] - 5652s 4s/step - loss: 0.9115 - accuracy: 0.6149 - val_loss: 0.8851 - val_accuracy: 0.6272\n",
      "Epoch 8/10\n",
      "1264/1264 [==============================] - 6069s 5s/step - loss: 0.8939 - accuracy: 0.6223 - val_loss: 0.8535 - val_accuracy: 0.6399\n",
      "Epoch 9/10\n",
      "1264/1264 [==============================] - 6167s 5s/step - loss: 0.8818 - accuracy: 0.6253 - val_loss: 0.8516 - val_accuracy: 0.6382\n",
      "Epoch 10/10\n",
      "1264/1264 [==============================] - 6163s 5s/step - loss: 0.8688 - accuracy: 0.6308 - val_loss: 0.8220 - val_accuracy: 0.6517\n",
      "208/208 [==============================] - 508s 2s/step - loss: 6.0721 - accuracy: 0.1541\n",
      "Test Loss: 6.072056770324707\n",
      "Test Accuracy: 0.15414664149284363\n"
     ]
    }
   ],
   "source": [
    "# CNN ResNet 버전\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_data_dir = 'E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반'\n",
    "valid_data_dir = 'E:\\PetData\\Data\\Training\\라벨링데이터\\TL2\\개\\안구\\일반'\n",
    "test_data_dir = 'E:\\PetData\\Data\\Validation\\LabelingData\\VL\\Dog\\Eye\\common'\n",
    "\n",
    "# 이미지 사이즈 및 배치 사이즈 설정\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터 증강을 위한 ImageDataGenerator 설정\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 훈련 데이터 로드 및 데이터 증강 적용\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "                                                    \n",
    "# 검증 데이터 로드 (증강 적용하지 않음)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# 테스트 데이터 로드 (증강 적용하지 않음)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "# 클래스 개수 추출\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "# ResNet_v2_152 모델 불러오기 (pre-trained weights 사용)\n",
    "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# 모델의 마지막 레이어 수정\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# 전체 모델 정의\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 기존의 가중치를 동결\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.samples // batch_size,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_generator.samples // batch_size,\n",
    "          epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b68f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
